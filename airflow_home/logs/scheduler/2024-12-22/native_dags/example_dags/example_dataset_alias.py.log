[2024-12-23T05:54:04.272+0700] {processor.py:186} INFO - Started process (PID=1867) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:54:04.274+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T05:54:04.281+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:04.279+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:54:04.482+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:54:05.812+0700] {processor.py:186} INFO - Started process (PID=1871) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:54:05.814+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T05:54:05.819+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:05.817+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:54:05.999+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:54:06.456+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.453+0700] {override.py:1911} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_producer
[2024-12-23T05:54:06.523+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.520+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_producer
[2024-12-23T05:54:06.584+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.582+0700] {override.py:1911} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_producer
[2024-12-23T05:54:06.679+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.676+0700] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_producer
[2024-12-23T05:54:06.738+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.736+0700] {override.py:1911} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_producer
[2024-12-23T05:54:06.792+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.790+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_producer
[2024-12-23T05:54:06.850+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.848+0700] {override.py:1911} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_producer
[2024-12-23T05:54:06.950+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:06.948+0700] {override.py:1911} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_consumer
[2024-12-23T05:54:07.004+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.001+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_consumer
[2024-12-23T05:54:07.059+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.057+0700] {override.py:1911} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_consumer
[2024-12-23T05:54:07.140+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.138+0700] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_consumer
[2024-12-23T05:54:07.194+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.192+0700] {override.py:1911} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_consumer
[2024-12-23T05:54:07.247+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.245+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_consumer
[2024-12-23T05:54:07.302+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.300+0700] {override.py:1911} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_consumer
[2024-12-23T05:54:07.398+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.397+0700] {override.py:1911} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_consumer
[2024-12-23T05:54:07.450+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.448+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_consumer
[2024-12-23T05:54:07.504+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.502+0700] {override.py:1911} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_consumer
[2024-12-23T05:54:07.587+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.584+0700] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_consumer
[2024-12-23T05:54:07.640+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.638+0700] {override.py:1911} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_consumer
[2024-12-23T05:54:07.695+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.693+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_consumer
[2024-12-23T05:54:07.746+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.744+0700] {override.py:1911} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_consumer
[2024-12-23T05:54:07.845+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.844+0700] {override.py:1911} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_producer
[2024-12-23T05:54:07.898+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.896+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_producer
[2024-12-23T05:54:07.955+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:07.953+0700] {override.py:1911} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_producer
[2024-12-23T05:54:08.049+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.047+0700] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_producer
[2024-12-23T05:54:08.060+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.059+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T05:54:08.082+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.080+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-12-23T05:54:08.087+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.084+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-12-23T05:54:08.091+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.089+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-12-23T05:54:08.095+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.093+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-12-23T05:54:08.107+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.106+0700] {override.py:1911} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_producer
[2024-12-23T05:54:08.116+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.114+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T05:54:08.120+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.118+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T05:54:08.124+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.123+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T05:54:08.127+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.126+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T05:54:08.166+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.164+0700] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_producer
[2024-12-23T05:54:08.256+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.254+0700] {override.py:1911} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_producer
[2024-12-23T05:54:08.259+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.258+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T05:54:08.291+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.289+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-12-23T05:54:08.294+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.293+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-12-23T05:54:08.299+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.297+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-12-23T05:54:08.302+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.301+0700] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-12-23T05:54:08.323+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.320+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T05:54:08.327+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.325+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T05:54:08.330+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.329+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T05:54:08.334+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.332+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T05:54:08.382+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.340+0700] {dagbag.py:698} ERROR - Failed to write serialized DAG: /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_consumer', '/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py', 36884373201407499, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_consumer", "start_date": 1609459200.0, "tags": ["consumer", "dataset"], "catchup": false, "tim ... (1528 characters truncated) ... [{"source": "dataset", "target": "dataset_s3_bucket_consumer", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2024-12-22 22:54:06.017802', '155ae07829798b239ebdcc67e1fc44dc', '/mnt/d/Project/airflow-news/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-12-23T05:54:08.400+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.388+0700] {dagbag.py:698} ERROR - Failed to write serialized DAG: /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_consumer', '/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py', 36884373201407499, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_consumer", "start_date": 1609459200.0, "tags": ["consumer", "dataset"], "catchup": false, "tim ... (1528 characters truncated) ... [{"source": "dataset", "target": "dataset_s3_bucket_consumer", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2024-12-22 22:54:06.017802', '155ae07829798b239ebdcc67e1fc44dc', '/mnt/d/Project/airflow-news/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-12-23T05:54:08.416+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.405+0700] {dagbag.py:698} ERROR - Failed to write serialized DAG: /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_consumer', '/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py', 36884373201407499, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_consumer", "start_date": 1609459200.0, "tags": ["consumer", "dataset"], "catchup": false, "tim ... (1528 characters truncated) ... [{"source": "dataset", "target": "dataset_s3_bucket_consumer", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2024-12-22 22:54:06.017802', '155ae07829798b239ebdcc67e1fc44dc', '/mnt/d/Project/airflow-news/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-12-23T05:54:08.433+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.421+0700] {dagbag.py:698} ERROR - Failed to write serialized DAG: /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_consumer', '/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py', 36884373201407499, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_consumer", "start_date": 1609459200.0, "tags": ["consumer", "dataset"], "catchup": false, "tim ... (1528 characters truncated) ... [{"source": "dataset", "target": "dataset_s3_bucket_consumer", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2024-12-22 22:54:06.017802', '155ae07829798b239ebdcc67e1fc44dc', '/mnt/d/Project/airflow-news/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-12-23T05:54:08.440+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:54:08.438+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T05:54:08.485+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 4.231 seconds
[2024-12-23T05:54:08.445+0700] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_consumer', '/mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py', 36884373201407499, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_consumer", "start_date": 1609459200.0, "tags": ["consumer", "dataset"], "catchup": false, "tim ... (1528 characters truncated) ... [{"source": "dataset", "target": "dataset_s3_bucket_consumer", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2024-12-22 22:54:06.017802', '155ae07829798b239ebdcc67e1fc44dc', '/mnt/d/Project/airflow-news/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-12-23T05:55:40.776+0700] {processor.py:186} INFO - Started process (PID=2166) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:55:40.778+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T05:55:40.783+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:55:40.781+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:55:40.957+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:55:41.026+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:55:41.025+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T05:55:41.057+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:55:41.056+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T05:55:41.065+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:55:41.063+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T05:55:41.070+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:55:41.069+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T05:55:41.076+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:55:41.075+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T05:55:41.158+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.397 seconds
[2024-12-23T05:57:12.805+0700] {processor.py:186} INFO - Started process (PID=2332) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:57:12.809+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T05:57:12.814+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:57:12.811+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:57:13.002+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:57:13.098+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:57:13.096+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T05:57:13.138+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:57:13.135+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T05:57:13.147+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:57:13.145+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T05:57:13.153+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:57:13.152+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T05:57:13.160+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:57:13.158+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T05:57:13.252+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.465 seconds
[2024-12-23T05:58:49.803+0700] {processor.py:186} INFO - Started process (PID=2569) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:58:49.805+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T05:58:49.810+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:58:49.808+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:58:50.010+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:58:50.084+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:58:50.082+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T05:58:50.115+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:58:50.113+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T05:58:50.122+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:58:50.121+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T05:58:50.129+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:58:50.127+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T05:58:50.135+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:58:50.133+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T05:58:50.224+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.437 seconds
[2024-12-23T05:59:38.184+0700] {processor.py:186} INFO - Started process (PID=2700) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:59:38.187+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T05:59:38.192+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:59:38.190+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:59:38.397+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T05:59:38.474+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:59:38.472+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T05:59:38.508+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:59:38.506+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T05:59:38.516+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:59:38.515+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T05:59:38.523+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:59:38.521+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T05:59:38.529+0700] {logging_mixin.py:190} INFO - [2024-12-23T05:59:38.527+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T05:59:38.615+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.448 seconds
[2024-12-23T06:00:34.370+0700] {processor.py:186} INFO - Started process (PID=2843) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:00:34.372+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:00:34.378+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:00:34.376+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:00:34.612+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:00:34.741+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:00:34.740+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:00:34.919+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:00:34.918+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:00:34.929+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:00:34.927+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:00:34.936+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:00:34.934+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:00:34.942+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:00:34.940+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:00:35.097+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.746 seconds
[2024-12-23T06:02:34.180+0700] {processor.py:186} INFO - Started process (PID=3103) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:02:34.183+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:02:34.189+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:02:34.187+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:02:34.391+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:02:34.470+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:02:34.469+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:02:34.508+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:02:34.507+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:02:34.516+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:02:34.515+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:02:34.522+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:02:34.521+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:02:34.529+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:02:34.527+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:02:34.617+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.457 seconds
[2024-12-23T06:04:42.165+0700] {processor.py:186} INFO - Started process (PID=3422) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:04:42.168+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:04:42.173+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:04:42.172+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:04:42.348+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:04:42.420+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:04:42.419+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:04:42.454+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:04:42.452+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:04:42.464+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:04:42.462+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:04:42.469+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:04:42.468+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:04:42.475+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:04:42.473+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:04:42.559+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.415 seconds
[2024-12-23T06:06:44.916+0700] {processor.py:186} INFO - Started process (PID=3721) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:06:44.918+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:06:44.925+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:06:44.923+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:06:45.128+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:06:45.220+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:06:45.219+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:06:45.261+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:06:45.260+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:06:45.271+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:06:45.270+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:06:45.278+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:06:45.277+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:06:45.285+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:06:45.284+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:06:45.380+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.499 seconds
[2024-12-23T06:07:48.917+0700] {processor.py:186} INFO - Started process (PID=3906) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:07:48.920+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:07:48.925+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:07:48.923+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:07:49.123+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:07:49.206+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:07:49.205+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:07:49.251+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:07:49.250+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:07:49.261+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:07:49.259+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:07:49.269+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:07:49.268+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:07:49.277+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:07:49.276+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:07:49.384+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.485 seconds
[2024-12-23T06:08:44.842+0700] {processor.py:186} INFO - Started process (PID=4084) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:08:44.845+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:08:44.851+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:08:44.848+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:08:45.089+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:08:45.180+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:08:45.178+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:08:45.223+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:08:45.221+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:08:45.233+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:08:45.231+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:08:45.241+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:08:45.239+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:08:45.248+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:08:45.246+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:08:45.345+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.527 seconds
[2024-12-23T06:12:00.896+0700] {processor.py:186} INFO - Started process (PID=4536) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:12:00.898+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:12:00.903+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:00.901+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:12:01.045+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:12:01.144+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:01.142+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:12:01.173+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:01.171+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:12:01.180+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:01.179+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:12:01.185+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:01.184+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:12:01.191+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:01.190+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:12:01.277+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.399 seconds
[2024-12-23T06:12:10.585+0700] {processor.py:186} INFO - Started process (PID=4557) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:12:10.587+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:12:10.593+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:10.592+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:12:10.773+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:12:10.844+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:10.842+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:12:10.890+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:10.888+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:12:10.902+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:10.900+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:12:10.909+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:10.907+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:12:10.918+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:12:10.916+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:12:11.006+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.441 seconds
[2024-12-23T06:13:38.098+0700] {processor.py:186} INFO - Started process (PID=4829) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:13:38.100+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:13:38.105+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:13:38.103+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:13:38.243+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:13:38.342+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:13:38.341+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:13:38.374+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:13:38.373+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:13:38.383+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:13:38.381+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:13:38.389+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:13:38.388+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:13:38.396+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:13:38.394+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:13:38.487+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.405 seconds
[2024-12-23T06:14:08.773+0700] {processor.py:186} INFO - Started process (PID=4899) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:14:08.775+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:14:08.780+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:14:08.778+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:14:08.954+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:14:09.022+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:14:09.021+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:14:09.052+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:14:09.050+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:14:09.059+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:14:09.058+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:14:09.064+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:14:09.063+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:14:09.069+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:14:09.068+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:14:09.142+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.392 seconds
[2024-12-23T06:15:13.183+0700] {processor.py:186} INFO - Started process (PID=5101) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:15:13.185+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:15:13.190+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:13.188+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:15:13.300+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:15:13.364+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:13.363+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:15:13.392+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:13.390+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:15:13.399+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:13.398+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:15:13.405+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:13.403+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:15:13.410+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:13.409+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:15:13.486+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.316 seconds
[2024-12-23T06:15:59.130+0700] {processor.py:186} INFO - Started process (PID=5224) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:15:59.136+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:15:59.146+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:59.143+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:15:59.461+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:15:59.548+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:59.547+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:15:59.589+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:59.588+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:15:59.598+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:59.597+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:15:59.605+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:59.604+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:15:59.612+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:15:59.611+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:15:59.726+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.656 seconds
[2024-12-23T06:17:53.556+0700] {processor.py:186} INFO - Started process (PID=5523) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:17:53.559+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:17:53.565+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:53.562+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:17:53.748+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:17:53.820+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:53.819+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:17:53.855+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:53.854+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:17:53.861+0700] {processor.py:186} INFO - Started process (PID=5524) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:17:53.863+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:17:53.864+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:53.862+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:17:53.867+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:53.865+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:17:53.869+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:53.868+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:17:53.876+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:53.874+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:17:53.973+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.439 seconds
[2024-12-23T06:17:54.025+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:17:54.108+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:54.106+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:17:54.148+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:54.145+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:17:54.158+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:54.156+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:17:54.167+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:54.165+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:17:54.185+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:17:54.183+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:17:54.286+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.442 seconds
[2024-12-23T06:19:26.856+0700] {processor.py:186} INFO - Started process (PID=5794) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:19:26.859+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:19:26.862+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:26.861+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:19:26.978+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:19:27.046+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:27.045+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:19:27.074+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:27.072+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:19:27.082+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:27.081+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:19:27.089+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:27.087+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:19:27.094+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:27.093+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:19:27.176+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.337 seconds
[2024-12-23T06:19:45.113+0700] {processor.py:186} INFO - Started process (PID=5848) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:19:45.115+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:19:45.120+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:45.119+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:19:45.281+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:19:45.351+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:45.350+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:19:45.387+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:45.386+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:19:45.395+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:45.393+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:19:45.401+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:45.399+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:19:45.408+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:19:45.406+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:19:45.497+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.404 seconds
[2024-12-23T06:20:51.674+0700] {processor.py:186} INFO - Started process (PID=6035) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:20:51.677+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:20:51.681+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:20:51.680+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:20:51.827+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:20:51.904+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:20:51.903+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:20:51.939+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:20:51.938+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:20:51.947+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:20:51.946+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:20:51.952+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:20:51.951+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:20:51.958+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:20:51.957+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:20:52.060+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.402 seconds
[2024-12-23T06:21:42.311+0700] {processor.py:186} INFO - Started process (PID=6158) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:21:42.320+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:21:42.331+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:21:42.327+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:21:42.577+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:21:42.672+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:21:42.670+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:21:42.726+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:21:42.724+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:21:42.734+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:21:42.733+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:21:42.742+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:21:42.740+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:21:42.748+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:21:42.747+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:21:42.844+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.572 seconds
[2024-12-23T06:23:16.072+0700] {processor.py:186} INFO - Started process (PID=6443) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:23:16.075+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:23:16.081+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:16.080+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:23:16.291+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:23:16.391+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:16.387+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:23:16.456+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:16.454+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:23:16.465+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:16.464+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:23:16.472+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:16.470+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:23:16.479+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:16.477+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:23:16.589+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.540 seconds
[2024-12-23T06:23:44.856+0700] {processor.py:186} INFO - Started process (PID=6524) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:23:44.858+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:23:44.862+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:44.861+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:23:45.071+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:23:45.150+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:45.149+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:23:45.189+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:45.187+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:23:45.207+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:45.206+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:23:45.214+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:45.213+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:23:45.220+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:23:45.219+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:23:45.314+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.481 seconds
[2024-12-23T06:24:49.835+0700] {processor.py:186} INFO - Started process (PID=6722) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:24:49.837+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:24:49.841+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:24:49.840+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:24:49.984+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:24:50.053+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:24:50.051+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:24:50.095+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:24:50.093+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:24:50.101+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:24:50.100+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:24:50.107+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:24:50.106+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:24:50.112+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:24:50.111+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:24:50.193+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.372 seconds
[2024-12-23T06:25:29.858+0700] {processor.py:186} INFO - Started process (PID=6861) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:25:29.860+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:25:29.866+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:25:29.865+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:25:30.055+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:25:30.126+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:25:30.125+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:25:30.163+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:25:30.162+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:25:30.171+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:25:30.169+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:25:30.177+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:25:30.176+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:25:30.183+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:25:30.181+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:25:30.270+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.434 seconds
[2024-12-23T06:26:21.305+0700] {processor.py:186} INFO - Started process (PID=7013) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:26:21.308+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:26:21.313+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:26:21.311+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:26:21.490+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:26:21.560+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:26:21.559+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:26:21.592+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:26:21.590+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:26:21.600+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:26:21.598+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:26:21.605+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:26:21.605+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:26:21.612+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:26:21.610+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:26:21.710+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.420 seconds
[2024-12-23T06:27:16.084+0700] {processor.py:186} INFO - Started process (PID=7176) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:27:16.086+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:27:16.092+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:16.091+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:27:16.246+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:27:16.319+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:16.318+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:27:16.356+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:16.355+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:27:16.364+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:16.363+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:27:16.371+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:16.369+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:27:16.377+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:16.376+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:27:16.463+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.399 seconds
[2024-12-23T06:27:56.750+0700] {processor.py:186} INFO - Started process (PID=7295) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:27:56.753+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:27:56.757+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:56.755+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:27:56.939+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:27:57.022+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:57.021+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:27:57.054+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:57.052+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:27:57.061+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:57.060+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:27:57.067+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:57.066+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:27:57.073+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:27:57.072+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:27:57.157+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.422 seconds
[2024-12-23T06:29:03.622+0700] {processor.py:186} INFO - Started process (PID=7491) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:29:03.625+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:29:03.630+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:03.628+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:29:03.809+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:29:03.878+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:03.877+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:29:03.910+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:03.909+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:29:03.919+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:03.917+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:29:03.926+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:03.924+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:29:03.932+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:03.931+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:29:04.018+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.417 seconds
[2024-12-23T06:29:31.663+0700] {processor.py:186} INFO - Started process (PID=7586) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:29:31.666+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:29:31.671+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:31.669+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:29:31.862+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:29:31.938+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:31.936+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:29:31.976+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:31.975+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:29:31.983+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:31.982+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:29:31.989+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:31.988+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:29:31.996+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:29:31.995+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:29:32.080+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.435 seconds
[2024-12-23T06:30:50.534+0700] {processor.py:186} INFO - Started process (PID=7808) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:30:50.536+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:30:50.541+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:50.540+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:30:50.703+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:30:50.771+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:50.770+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:30:50.804+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:50.803+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:30:50.811+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:50.810+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:30:50.817+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:50.816+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:30:50.822+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:50.820+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:30:50.892+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.378 seconds
[2024-12-23T06:30:58.581+0700] {processor.py:186} INFO - Started process (PID=7827) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:30:58.583+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:30:58.588+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:58.586+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:30:58.752+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:30:58.815+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:58.813+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:30:58.847+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:58.846+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:30:58.854+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:58.853+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:30:58.859+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:58.858+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:30:58.865+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:30:58.864+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:30:58.939+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.371 seconds
[2024-12-23T06:32:32.684+0700] {processor.py:186} INFO - Started process (PID=8111) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:32:32.687+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:32:32.693+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:32.691+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:32:32.893+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:32:33.023+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:33.016+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:32:33.101+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:33.100+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:32:33.110+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:33.108+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:32:33.117+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:33.116+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:32:33.124+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:33.123+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:32:33.236+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.568 seconds
[2024-12-23T06:32:41.344+0700] {processor.py:186} INFO - Started process (PID=8138) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:32:41.347+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:32:41.353+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:41.351+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:32:41.543+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:32:41.616+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:41.615+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:32:41.653+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:41.651+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:32:41.662+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:41.660+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:32:41.669+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:41.668+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:32:41.675+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:32:41.674+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:32:41.789+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.467 seconds
[2024-12-23T06:34:07.478+0700] {processor.py:186} INFO - Started process (PID=8407) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:34:07.481+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:34:07.486+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:07.484+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:34:07.648+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:34:07.717+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:07.716+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:34:07.748+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:07.747+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:34:07.756+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:07.754+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:34:07.762+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:07.760+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:34:07.768+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:07.766+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:34:07.855+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.390 seconds
[2024-12-23T06:34:26.051+0700] {processor.py:186} INFO - Started process (PID=8454) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:34:26.053+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:34:26.057+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:26.056+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:34:26.244+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:34:26.318+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:26.316+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:34:26.357+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:26.356+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:34:26.364+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:26.363+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:34:26.370+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:26.369+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:34:26.376+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:34:26.375+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:34:26.456+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.426 seconds
[2024-12-23T06:36:50.941+0700] {processor.py:186} INFO - Started process (PID=8880) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:36:50.943+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:36:50.947+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:36:50.946+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:36:51.085+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:36:51.154+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:36:51.153+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:36:51.192+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:36:51.191+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:36:51.200+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:36:51.199+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:36:51.206+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:36:51.205+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:36:51.222+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:36:51.221+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:36:51.313+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.393 seconds
[2024-12-23T06:37:10.748+0700] {processor.py:186} INFO - Started process (PID=8937) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:37:10.750+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:37:10.755+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:37:10.754+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:37:10.936+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:37:11.009+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:37:11.007+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:37:11.046+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:37:11.044+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:37:11.053+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:37:11.051+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:37:11.059+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:37:11.057+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:37:11.065+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:37:11.064+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:37:11.165+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.432 seconds
[2024-12-23T06:38:48.597+0700] {processor.py:186} INFO - Started process (PID=9272) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:38:48.601+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:38:48.607+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:48.605+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:38:48.849+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:38:48.941+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:48.940+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:38:48.987+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:48.985+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:38:48.998+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:48.996+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:38:49.008+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:49.006+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:38:49.016+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:49.014+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:38:49.147+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.570 seconds
[2024-12-23T06:38:55.547+0700] {processor.py:186} INFO - Started process (PID=9299) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:38:55.550+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:38:55.556+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:55.554+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:38:55.755+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:38:55.829+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:55.828+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:38:55.867+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:55.866+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:38:55.876+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:55.875+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:38:55.882+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:55.881+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:38:55.889+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:38:55.887+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:38:55.982+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.459 seconds
[2024-12-23T06:40:53.035+0700] {processor.py:186} INFO - Started process (PID=9614) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:40:53.037+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:40:53.041+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:40:53.040+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:40:53.217+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:40:53.290+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:40:53.289+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:40:53.331+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:40:53.329+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:40:53.340+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:40:53.339+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:40:53.347+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:40:53.345+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:40:53.353+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:40:53.351+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:40:53.440+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.426 seconds
[2024-12-23T06:42:50.663+0700] {processor.py:186} INFO - Started process (PID=9877) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:42:50.665+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:42:50.671+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:42:50.669+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:42:50.844+0700] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:42:50.910+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:42:50.909+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:42:50.940+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:42:50.939+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:42:50.948+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:42:50.947+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:42:50.955+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:42:50.954+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:42:50.962+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:42:50.960+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:42:51.085+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.444 seconds
[2024-12-23T06:44:51.189+0700] {processor.py:186} INFO - Started process (PID=10277) to work on /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:44:51.191+0700] {processor.py:914} INFO - Processing file /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-12-23T06:44:51.196+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:44:51.195+0700] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:44:51.392+0700] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-12-23T06:44:51.464+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:44:51.462+0700] {dag.py:3239} INFO - Sync 4 DAGs
[2024-12-23T06:44:51.501+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:44:51.499+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-12-23T06:44:51.508+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:44:51.507+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-12-23T06:44:51.513+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:44:51.512+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-12-23T06:44:51.519+0700] {logging_mixin.py:190} INFO - [2024-12-23T06:44:51.518+0700] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-12-23T06:44:51.611+0700] {processor.py:208} INFO - Processing /mnt/d/Project/airflow-news/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.447 seconds
